# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wbY1u12HlvBcXalO7GjqYF6NMkBVnEqn
"""

# STEP 1: Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,
                             roc_curve, ConfusionMatrixDisplay, RocCurveDisplay)
from imblearn.over_sampling import SMOTE

# STEP 2: Load and clean data
file_path = 'resume.csv'  # <- update if needed
df = pd.read_csv(file_path)

cols_to_drop = ['job_ad_id', 'job_link', 'job_fed_contractor', 'job_equal_opp_employer']
df.drop(columns=cols_to_drop, inplace=True, errors='ignore')

binary_cols = [
    'job_req_any', 'job_req_communication', 'job_req_education', 'job_req_computer',
    'job_req_organization', 'job_req_school', 'received_callback', 'college_degree',
    'honors', 'worked_during_school', 'computer_skills', 'special_skills',
    'volunteer', 'military', 'employment_holes', 'has_email_address']

for col in binary_cols:
    if col in df.columns:
        df[col] = df[col].astype(str).str.strip().str.lower().map({'yes': 1, 'no': 0, '1': 1, '0': 0})

if 'gender' in df.columns:
    df['gender'] = df['gender'].str.lower().map({'m': 1, 'f': 0})

if 'race' in df.columns:
    df['race'] = df['race'].astype('category').cat.codes

for col in df.columns:
    if df[col].dtype in ['float64', 'int64']:
        df[col] = df[col].fillna(-1)
    elif df[col].dtype == 'object':
        df[col] = df[col].fillna('Unknown')

# STEP 3: EDA
sns.countplot(x='resume_quality', data=df)
plt.title("Resume Quality Distribution")
plt.show()

if 'gender' in df.columns:
    df['gender_label'] = df['gender'].map({1: 'Male', 0: 'Female'})
    sns.barplot(data=df, x='gender_label', y='received_callback')
    plt.title("Callback Rate by Gender")
    plt.xlabel("Gender")
    plt.ylabel("Callback Rate")
    plt.show()

if 'race' in df.columns:
    df['race_label'] = df['race'].map({0: 'White-sounding', 1: 'Black-sounding'})
    sns.barplot(data=df, x='race_label', y='received_callback')
    plt.title("Callback Rate by Race")
    plt.xlabel("Race")
    plt.ylabel("Callback Rate")
    plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

# STEP 4: Chi-Square Tests
race_table = pd.crosstab(df['race'], df['received_callback'])
chi2_race, p_race, _, _ = chi2_contingency(race_table)
print("Race vs. Callback:\n", race_table)
print(f"Chi2 = {chi2_race:.4f}, p-value = {p_race:.4f}\n")

gender_table = pd.crosstab(df['gender'], df['received_callback'])
chi2_gender, p_gender, _, _ = chi2_contingency(gender_table)
print("Gender vs. Callback:\n", gender_table)
print(f"Chi2 = {chi2_gender:.4f}, p-value = {p_gender:.4f}\n")

# STEP 5: Logistic Regression
X = df.drop(columns=['received_callback'])
y = df['received_callback']
cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

preprocessor = ColumnTransformer([
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
], remainder='passthrough')

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))
])

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)
y_proba = pipeline.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_proba)

print("Logistic Regression Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, zero_division=0))
print(f"ROC AUC Score: {roc_auc:.4f}")

ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
plt.title("Confusion Matrix â€“ Logistic Regression (Baseline Model")
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

# STEP 6: Random Forest
X_train_rf = pd.get_dummies(X_train, drop_first=True)
X_test_rf = pd.get_dummies(X_test, drop_first=True)
X_train_rf, X_test_rf = X_train_rf.align(X_test_rf, join='left', axis=1, fill_value=0)

rf = RandomForestClassifier(class_weight='balanced', random_state=42)
rf.fit(X_train_rf, y_train)
y_pred = rf.predict(X_test_rf)
y_proba = rf.predict_proba(X_test_rf)[:, 1]

print("Random Forest Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}")

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='viridis')
plt.title("Random Forest Confusion Matrix")
plt.show()

RocCurveDisplay.from_estimator(rf, X_test_rf, y_test)
plt.title("Random Forest ROC Curve")
plt.show()

# STEP 7: SMOTE - Remove 'firstname'
X = df.drop(columns=['received_callback', 'firstname'])
y = df['received_callback']

for col in X.select_dtypes(include='object').columns:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

rf_fair = RandomForestClassifier(class_weight='balanced', random_state=42)
rf_fair.fit(X_train_res, y_train_res)
y_pred = rf_fair.predict(X_test)
y_prob = rf_fair.predict_proba(X_test)[:, 1]

print("Confusion Matrix (No Firstname):\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}")

RocCurveDisplay.from_estimator(rf_fair, X_test, y_test)
plt.title("Random Forest ROC Curve (No Firstname)")
plt.show()

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='coolwarm')
plt.title("Confusion Matrix (No Firstname)")
plt.show()

feat_imp_df = pd.DataFrame({
    'Feature': X_train_res.columns,
    'Importance': rf_fair.feature_importances_
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(feat_imp_df['Feature'][:10][::-1], feat_imp_df['Importance'][:10][::-1])
plt.xlabel("Importance")
plt.title("Top 10 Feature Importances (No Firstname)")
plt.tight_layout()
plt.show()